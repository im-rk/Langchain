{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a45994ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c53e472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000022B83FCEEF0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000022B83FCEE00>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"llama-3.1-8b-instant\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a250d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Ramkumar! It's great to hear that you're pursuing a degree in Computer Science and AI. That's a fascinating field with a lot of exciting opportunities for innovation and growth.\\n\\nWhat aspects of Computer Science and AI interest you the most? Are you more into machine learning, natural language processing, computer vision, or something else?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 57, 'total_tokens': 130, 'completion_time': 0.094928431, 'prompt_time': 0.002718403, 'queue_time': 0.055799477, 'total_time': 0.097646834}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--138136f4-8c0d-4ca2-8a15-766350a0543b-0', usage_metadata={'input_tokens': 57, 'output_tokens': 73, 'total_tokens': 130})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi , I am Ramkumar. I am a college student, pursuing a degree in Computer Science and AI\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56b5c210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Ramkumar, and you are a college student, pursuing a degree in Computer Science and Artificial Intelligence (AI).', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 135, 'total_tokens': 162, 'completion_time': 0.038895003, 'prompt_time': 0.007355928, 'queue_time': 0.049279622, 'total_time': 0.046250931}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--c8f93f05-8805-4eca-ac2d-e89d711e91a5-0', usage_metadata={'input_tokens': 135, 'output_tokens': 27, 'total_tokens': 162})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi , I am Ramkumar. I am a college student, pursuing a degree in Computer Science and AI\"),\n",
    "    AIMessage(content=\"Nice to meet you, Ramkumar. It's great to hear that you're pursuing a degree in Computer Science and AI. Those are exciting and in-demand fields. What specific areas of AI are you interested in, or are you taking a more general course load in computer science?\"),\n",
    "    HumanMessage(content=\"Hey what is my name,what i am doing?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a82bedbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e429a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35e6dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, I am Ramkumar K R and I am college student, pursuing a degree in CSE-AI\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ba11805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Ramkumar K R, nice to meet you. It's great to hear that you're pursuing a degree in Computer Science Engineering with a specialization in Artificial Intelligence (CSE-AI). AI has a wide range of applications and is a rapidly growing field, I'm sure you must be excited about your studies.\\n\\nWhat specific areas of AI are you interested in? Are you working on any projects or participating in any competitions related to AI? I'm here to help and answer any questions you may have.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcf579f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Ramkumar K R.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fda09e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have any information about your name. I'm a large language model, I don't have the ability to know or store personal information about individual users. Each time you interact with me, it's a new conversation and I don't retain any information from previous conversations. If you'd like to share your name with me, I'd be happy to chat with you!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aacb98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi John, it was nice to meet you. Since I don't retain any information from previous conversations, I won't remember your name if you come back later. However, this conversation will be a fresh start, and I'll be happy to chat with you about anything on your mind. What's on your agenda today, John?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey My name is John\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37f610d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's easy, John. Your name is John.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f21bce",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d318be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.Answer all the question to the next of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76e1b285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Ramkumar K R. I'm happy to assist you with any questions or information you may need. How can I help you today?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 60, 'total_tokens': 94, 'completion_time': 0.042294448, 'prompt_time': 0.003153205, 'queue_time': 0.053987995, 'total_time': 0.045447653}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--008b7584-0519-41e6-aa5d-1fcbe330e45d-0', usage_metadata={'input_tokens': 60, 'output_tokens': 34, 'total_tokens': 94})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Ramkumar K R\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed12facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90634f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Ramkumar K R. How can I assist you today?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response=with_message_history.invoke([HumanMessage(content=\"Hi my name is Ramkumar K R\")],config=config)\n",
    "response.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c63cd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Ramkumar K R.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke([HumanMessage(content=\"What is my name?\")],config=config)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1847ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a606f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7c4fa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'வணக்கம் Ramkumar! மீண்டும் வணக்கம். நீங்கள் இப்போது என்ன செய்ய வேண்டும் என்று நினைக்கிறீர்கள்?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history,input_messages_key=\"messages\")\n",
    "response=with_message_history.invoke({\"messages\":[HumanMessage(content=\"HI i am Ramkumar.\")],\"language\":\"Tamil\"},\n",
    "                                     config=config)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a1fba02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GEN-AI\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ramku\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cf9bb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have any information about your personal preferences, so I couldn't tell you what ice cream you like. Do you have a favorite flavor?\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    |prompt|model\n",
    ")\n",
    "response=chain.invoke({\n",
    "    \"messages\":messages+[HumanMessage(content=\"What ice cream do i like\")],\n",
    "    \"language\":\"English\"\n",
    "})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c182549e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked for the solution to the math problem \"2 + 2\".'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\n",
    "    \"messages\":messages+[HumanMessage(content=\"What math problem did i ask?\")],\n",
    "    \"language\":\"English\"\n",
    "})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86a84dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets wrap this in the MEssage History\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "config={\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2737f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You didn't tell me your name. Would you like to share it with me?\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"whats my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abffa641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You didn't ask a math problem. Our conversation started with a question about having fun, and then you asked about your name and a non-existent math problem. If you have a math problem you'd like to ask, I'd be happy to help.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"what math problem did i ask?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf777b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
